<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Documentación del Proyecto: Buscador de Medicamentos</title>
    <style>
        body { 
            font-family: Arial, sans-serif; 
            line-height: 1.6; 
            margin: 20px; 
            background-color: #ffffff; 
            color: #000000; 
        }
        .container { 
            max-width: 900px; 
            margin: auto; 
            padding: 20px; 
        }
        h1, h2, h3 { 
            color: #000000; 
            border-bottom: 1px solid #cccccc;
            padding-bottom: 5px;
        }
        h1 {
            text-align: center;
            border-bottom-width: 2px;
        }
        h2 { 
            margin-top: 35px; 
        }
        code { 
            font-family: "Courier New", Courier, monospace;
            font-size: 0.95em;
        }
        pre { 
            font-family: "Courier New", Courier, monospace;
            padding: 10px; 
            border: 1px solid #dddddd;
            white-space: pre-wrap;
            word-wrap: break-word;
            background-color: #f9f9f9;
        }
        .link-container { 
            margin: 30px 0; 
            padding: 15px; 
            border: 1px solid #cccccc;
        }
        table { 
            width: 100%; 
            border-collapse: collapse; 
            margin-top: 20px; 
        }
        th, td { 
            border: 1px solid #cccccc; 
            padding: 8px; 
            text-align: left; 
        }
        th { 
            background-color: #f2f2f2; 
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Análisis y Desarrollo del Buscador de Medicamentos</h1>

        <div class="link-container">
            <h3>Enlace a la Aplicación Funcional</h3>
            <p>La aplicación está desplegada en un servidor externo y se puede acceder desde cualquier dispositivo copiando y pegando la siguiente URL en un navegador:</p>
            <p><strong><code>https://79259f59-89c3-4c6f-8713-7eb1b6153d02-00-daplll22n1wu.kirk.replit.dev/</code></strong></p>
        </div>

        <h2>1. Metodología General del Proyecto</h2>
        <p>El proyecto se estructuró en cuatro fases principales, abarcando desde la recolección de datos hasta la puesta en producción de una herramienta interactiva.</p>
        <ol>
            <li><strong>Fase 1: Extracción de Datos (Web Scraping):</strong> Se desarrollaron scripts en Python con la librería <code>Selenium</code> para automatizar la navegación y extracción de datos de dos sitios web de farmacias peruanas.</li>
            <li><strong>Fase 2: Procesamiento y Unificación de Datos:</strong> Los datos crudos (raw data) obtenidos se procesaron, limpiaron y unificaron en un único dataset coherente utilizando la librería <code>Pandas</code>.</li>
            <li><strong>Fase 3: Desarrollo de la Aplicación Web:</strong> Se construyó el motor de la aplicación con el framework <code>Flask</code>, que sirve como backend para la lógica de búsqueda y la integración con APIs externas.</li>
            <li><strong>Fase 4: Despliegue y Acceso Público:</strong> La aplicación final se desplegó en la plataforma <code>Replit</code> para garantizar su disponibilidad y acceso a través de un enlace web público.</li>
        </ol>

        <h2>2. Fase de Extracción de Datos (Web Scraping)</h2>
        <p>Se implementaron dos scrapers distintos, cada uno adaptado a las particularidades del sitio web objetivo.</p>
        
        <h3>2.1. Scraper para 'Boticas y Salud'</h3>
        <ul>
            <li><strong>Tecnología:</strong> Selenium con el driver <code>geckodriver</code> para controlar Firefox.</li>
            <li><strong>Estrategia de Extracción:</strong>
                <ol>
                    <li>Navegación a la URL del catálogo de medicamentos.</li>
                    <li>Implementación de un bucle de <strong>scroll infinito</strong> para forzar la carga dinámica de todos los productos en la página. El script simula el desplazamiento del usuario hasta que la altura de la página deja de aumentar.</li>
                    <li>Una vez cargados todos los productos, se extraen los datos de cada "tarjeta de producto" (nombre, precio y principio activo) utilizando selectores CSS.</li>
                </ol>
            </li>
            <li><strong>Fragmento de Código Clave (Scroll Infinito):</strong></li>
            <pre>
# Bucle para simular el scroll y cargar todos los productos
last_height = driver.execute_script("return document.body.scrollHeight")
while True:
    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
    time.sleep(2) # Pausa para permitir la carga
    new_height = driver.execute_script("return document.body.scrollHeight")
    if new_height == last_height:
        break # Se detiene si ya no hay más contenido
    last_height = new_height
            </pre>
        </ul>

        <h3>2.2. Scraper para 'Hogar y Salud'</h3>
        <ul>
            <li><strong>Tecnología:</strong> Selenium con <code>chromedriver</code> para controlar Google Chrome.</li>
            <li><strong>Estrategia de Extracción:</strong>
                <ol>
                    <li>Se identificó una estructura de <strong>paginación</strong> (/page/1/, /page/2/, etc.). Se implementó un bucle que incrementa el número de página hasta no encontrar más productos.</li>
                    <li>En cada página de listado, se extraen los enlaces individuales de cada producto.</li>
                    <li>El script visita cada enlace de producto en una nueva pestaña para acceder a la página de detalle, donde se encuentra la información completa (nombre, precio y composición).</li>
                    <li>Se implementó un manejo de excepciones robusto para continuar el proceso incluso si un producto individual falla.</li>
                </ol>
            </li>
            <li><strong>Fragmento de Código Clave (Paginación y Visita a Detalle):</strong></li>
            <pre>
# Bucle para iterar a través de las páginas del catálogo
while True:
    driver.get(base_url.format(page))
    enlaces_productos = driver.find_elements(By.CSS_SELECTOR, "h3.wd-entities-title a")
    if not enlaces_productos:
        break # Fin del scraping si no hay más productos
    
    urls_a_visitar = [enlace.get_attribute("href") for enlace in enlaces_productos]
    
    for url_producto in urls_a_visitar:
        # Lógica para abrir en nueva pestaña, extraer datos y cerrar...
    
    page += 1
            </pre>
        </ul>
        
        <h2>3. Fase de Procesamiento y Unificación</h2>
        <p>El script responsable de esta fase toma los datos crudos y los prepara para la aplicación.</p>
        <ul>
            <li><strong>Librería Principal:</strong> <code>Pandas</code>.</li>
            <li><strong>Proceso:</strong>
                <ol>
                    <li>Carga de los dos archivos CSV generados por los scrapers.</li>
                    <li>Añadir una columna <code>Fuente</code> a cada DataFrame para identificar el origen de cada registro.</li>
                    <li>Concatenar ambos DataFrames en uno solo usando <code>pd.concat()</code>.</li>
                    <li>Realizar una limpieza de datos esencial: eliminar filas sin producto o precio, rellenar valores nulos y eliminar duplicados.</li>
                    <li>Guardar el DataFrame limpio y unificado, que servirá como base de datos para la aplicación web.</li>
                </ol>
            </li>
        </ul>

        <h2>4. Fase de Desarrollo de la Aplicación Web</h2>
        <p>El corazón del proyecto es una aplicación Flask que gestiona la lógica de búsqueda y la presentación de resultados.</p>
        <table>
            <tr>
                <th>Componente</th>
                <th>Descripción</th>
            </tr>
            <tr>
                <td><strong>Flask</strong></td>
                <td>Microframework de Python utilizado para construir el backend y gestionar las rutas y peticiones.</td>
            </tr>
            <tr>
                <td><strong>Pandas</strong></td>
                <td>Al iniciar la aplicación, se carga el CSV unificado en un DataFrame. Las búsquedas locales se realizan sobre este DataFrame en memoria.</td>
            </tr>
            <tr>
                <td><strong>Requests</strong></td>
                <td>Librería utilizada para realizar la petición HTTP a la API de OpenFDA.</td>
            </tr>
            <tr>
                <td><strong>Deep-Translator</strong></td>
                <td>Se utiliza para traducir al español los resultados en inglés de la API de OpenFDA.</td>
            </tr>
            <tr>
                <td><strong>HTML / Jinja2</strong></td>
                <td>Se implementó una <strong>renderización del lado del servidor</strong>. Flask y Jinja2 inyectan los resultados de la búsqueda directamente en el HTML antes de enviarlo al navegador, eliminando la necesidad de JavaScript en el cliente para esta tarea.</td>
            </tr>
        </table>

        <h2>5. Fase de Despliegue en Replit</h2>
        <p>Para hacer la aplicación accesible públicamente, se eligió la plataforma Replit.</p>
        <ul>
            <li><strong>Entorno Contenerizado:</strong> Replit ejecuta el proyecto en un contenedor, instalando las dependencias del archivo <code>requirements.txt</code>.</li>
            <li><strong>Exposición de Puertos:</strong> Al ejecutar Flask con <code>host='0.0.0.0'</code>, Replit detecta el puerto abierto y lo redirige a una URL pública.</li>
            <li><strong>Ciclo de Vida "Dormir/Despertar":</strong> El plan gratuito mantiene la aplicación "dormida" tras un período de inactividad, "despertándola" automáticamente en la siguiente visita.</li>
        </ul>

    </div>
</body>
</html>